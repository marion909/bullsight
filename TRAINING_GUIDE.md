# ğŸ¯ BullSight Erkennungs-Training & Optimierung

## Ãœberblick

BullSight verwendet **differenzbasierte Computer Vision** (nicht Machine Learning). Die "Training" besteht aus:
1. Erstellen eines perfekten Referenzbildes
2. Optimieren der Erkennungsparameter
3. Testen unter verschiedenen Bedingungen

## ğŸ“¸ Schritt 1: Perfektes Referenzbild erstellen

### Voraussetzungen
- âœ… Dartboard ist vollstÃ¤ndig leer (keine Pfeile!)
- âœ… Beleuchtung ist optimal und gleichmÃ¤ÃŸig
- âœ… Kamera ist montiert und fokussiert
- âœ… Keine Schatten auf dem Board

### Methode A: Ãœber die UI (empfohlen)

1. Starte BullSight: `./run.sh` (Linux/Raspberry Pi) oder `.\run.bat` (Windows)
2. Navigiere zu **Settings** â†’ **Calibration**
3. Stelle sicher, dass das Dartboard **komplett leer** ist (keine Darts!)
4. Klicke auf **"Capture Reference Image"**
5. BestÃ¤tige den Dialog
6. Warte 3 Sekunden wÃ¤hrend die Kamera fokussiert
7. âœ… Referenzbild wird automatisch gespeichert nach `config/reference_board.jpg`

Die UI-Methode:
- Triggert automatisch Autofokus
- Nimmt 10 Frames und wÃ¤hlt das stabilste
- Speichert direkt im korrekten Format
- Zeigt Erfolgsmeldung mit Speicherort

### Methode B: Manuell via Python

```python
from src.vision.camera_manager import CameraManager
from src.vision.dart_detector import DartDetector
from pathlib import Path

# 1. Initialisiere Komponenten
camera = CameraManager(resolution=(1280, 720), enable_autofocus=True)
detector = DartDetector()

# 2. Starte Kamera und fokussiere
camera.start()
camera.trigger_autofocus()  # Warte 2-3 Sekunden
import time
time.sleep(3)

# 3. Capture mehrere Frames und nimm das beste
frames = []
for i in range(10):
    frame = camera.capture_frame()
    frames.append(frame)
    time.sleep(0.1)

# 4. WÃ¤hle Frame mit geringstem Rauschen (mittlere Frame)
reference_frame = frames[5]

# 5. Setze als Referenz und speichere
detector.set_reference_image(reference_frame)
detector.save_reference_to_file("config/reference_board.jpg")

# 6. AufrÃ¤umen
camera.stop()

print("âœ… Referenzbild gespeichert!")
```

### Methode C: Ãœber Terminal

```bash
# Erstelle ein Script
cat > capture_reference.py << 'EOF'
import sys
sys.path.insert(0, '.')
from src.vision.camera_manager import CameraManager
from src.vision.dart_detector import DartDetector
import time

camera = CameraManager()
detector = DartDetector()

print("ğŸ“¸ Capturing reference image in 5 seconds...")
print("   Make sure dartboard is EMPTY!")
time.sleep(5)

camera.start()
time.sleep(2)  # Autofocus

frame = camera.capture_frame()
detector.set_reference_image(frame)
detector.save_reference_to_file("config/reference_board.jpg")

camera.stop()
print("âœ… Reference image saved to config/reference_board.jpg")
EOF

# AusfÃ¼hren
export PYTHONPATH="$(pwd)"
python capture_reference.py
```

## âš™ï¸ Schritt 2: Parameter optimieren

### Die wichtigsten Parameter

```python
detector = DartDetector(
    min_contour_area=100,      # Minimum Dart-GrÃ¶ÃŸe
    max_contour_area=5000,     # Maximum Dart-GrÃ¶ÃŸe
    blur_kernel_size=5,        # Rauschfilter
    threshold_value=30         # Empfindlichkeit
)
```

### Parameter-Guide

#### 1. `threshold_value` (Empfindlichkeit)
**Was es tut**: Bestimmt, wie groÃŸ der Unterschied sein muss

- **Zu niedrig (10-20)**: Erkennt zu viele falsche Darts (Schatten, Bewegungen)
- **Optimal (25-40)**: ZuverlÃ¤ssige Erkennung
- **Zu hoch (50+)**: Verpasst echte Darts

**Anpassen fÃ¼r:**
- ğŸ”† Helle Umgebung: 35-45
- ğŸŒ™ Dunkle Umgebung: 25-35
- ğŸ’¡ Wechselndes Licht: 30-40

#### 2. `min_contour_area` (MinimalgrÃ¶ÃŸe)
**Was es tut**: Filtert kleine StÃ¶rungen heraus

- **Zu niedrig (<50)**: Viele Fehlerkennungen
- **Optimal (100-200)**: Gut fÃ¼r Standard-Darts
- **Zu hoch (>300)**: Verpasst Dart-Spitzen

**Anpassen fÃ¼r:**
- Entfernung Kamera â†’ Board: NÃ¤her = grÃ¶ÃŸere Werte
- Dart-Typ: DÃ¼nne Spitzen = kleinere Werte

#### 3. `max_contour_area` (MaximalgrÃ¶ÃŸe)
**Was es tut**: Filtert groÃŸe Objekte (Hand, Schatten)

- **Zu niedrig (<3000)**: Verpasst breite Darts
- **Optimal (4000-6000)**: Standard-Darts
- **Zu hoch (>8000)**: Erkennt HÃ¤nde/Schatten

#### 4. `blur_kernel_size` (Rauschfilter)
**Was es tut**: GlÃ¤ttet Bild vor Vergleich

- **Klein (3)**: Mehr Details, mehr Rauschen
- **Optimal (5-7)**: Gute Balance
- **GroÃŸ (9+)**: Weniger Rauschen, weniger Details

## ğŸ§ª Schritt 3: Testing & Optimierung

### Test-Script erstellen

```python
# test_detection.py
import sys
sys.path.insert(0, '.')
from src.vision.camera_manager import CameraManager
from src.vision.dart_detector import DartDetector
import time

# Parameter zum Testen
TEST_PARAMS = [
    {"threshold": 25, "min_area": 100, "max_area": 5000},
    {"threshold": 30, "min_area": 150, "max_area": 5000},
    {"threshold": 35, "min_area": 100, "max_area": 4000},
]

camera = CameraManager()
camera.start()

# Lade Referenzbild
reference_detector = DartDetector()
reference_detector.load_reference_from_file("config/reference_board.jpg")

print("ğŸ¯ Wirf jetzt einen Dart!")
time.sleep(5)

current_frame = camera.capture_frame()

# Teste verschiedene Parameter
for i, params in enumerate(TEST_PARAMS, 1):
    detector = DartDetector(
        min_contour_area=params["min_area"],
        max_contour_area=params["max_area"],
        threshold_value=params["threshold"]
    )
    detector.set_reference_image(reference_detector.reference_image)
    
    result = detector.detect_dart(current_frame)
    
    print(f"\n--- Test {i} ---")
    print(f"Parameters: {params}")
    if result:
        print(f"âœ… Dart detected at ({result.x}, {result.y})")
        print(f"   Confidence: {result.confidence:.2f}")
        print(f"   Area: {result.contour_area:.0f}")
    else:
        print("âŒ No dart detected")

camera.stop()
```

### Systematisches Testen

```bash
# 1. Verschiedene Beleuchtungen
./test_detection.py  # Tageslicht
./test_detection.py  # Kunstlicht
./test_detection.py  # DÃ¤mmerlicht

# 2. Verschiedene Positionen
# Dart in Bullseye
# Dart in Triple 20
# Dart in Double-Ring
# Dart am Rand

# 3. Verschiedene Dart-Typen
# Steeldarts (dÃ¼nn)
# Softdarts (dick)
# Verschiedene Farben
```

## ğŸ“Š Schritt 4: Live-Tuning

### Visualisierung wÃ¤hrend der Erkennung

```python
# live_tuning.py
import sys
sys.path.insert(0, '.')
from src.vision.camera_manager import CameraManager
from src.vision.dart_detector import DartDetector
import cv2

camera = CameraManager()
detector = DartDetector()
detector.load_reference_from_file("config/reference_board.jpg")

camera.start()

print("ğŸ¯ Live Tuning Mode")
print("   Adjust parameters and see results in real-time")
print("   Press 'q' to quit")

# Trackbars fÃ¼r Parameter
cv2.namedWindow("Tuning")
cv2.createTrackbar("Threshold", "Tuning", 30, 100, lambda x: None)
cv2.createTrackbar("Min Area", "Tuning", 100, 500, lambda x: None)
cv2.createTrackbar("Max Area", "Tuning", 5000, 10000, lambda x: None)

while True:
    # Hole aktuelle Parameter
    threshold = cv2.getTrackbarPos("Threshold", "Tuning")
    min_area = cv2.getTrackbarPos("Min Area", "Tuning")
    max_area = cv2.getTrackbarPos("Max Area", "Tuning")
    
    # Update Detector
    detector.threshold_value = threshold
    detector.min_contour_area = min_area
    detector.max_contour_area = max_area
    
    # Capture und erkenne
    frame = camera.capture_frame()
    result = detector.detect_dart(frame)
    
    # Visualisiere
    vis = detector.visualize_detection(frame, result)
    
    # Zeige Info
    info_text = f"T:{threshold} Min:{min_area} Max:{max_area}"
    cv2.putText(vis, info_text, (10, 30), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
    
    if result:
        cv2.putText(vis, f"Dart at ({result.x}, {result.y})", (10, 60),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
    
    cv2.imshow("Tuning", vis)
    
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

camera.stop()
cv2.destroyAllWindows()

print(f"\nâœ… Optimale Parameter gefunden:")
print(f"   threshold_value={threshold}")
print(f"   min_contour_area={min_area}")
print(f"   max_contour_area={max_area}")
```

## ğŸ’¡ Best Practices

### Beleuchtung
- âœ… **GleichmÃ¤ÃŸige Ausleuchtung**: Keine Schatten
- âœ… **Konstante Beleuchtung**: Keine wechselnden LichtverhÃ¤ltnisse
- âœ… **Kein Blitz**: Kontinuierliches Licht
- âŒ **Vermeiden**: Direkte Sonne, blinkende Lichter

### Kamera-Setup
- âœ… **Autofokus aktiviert**: Scharfes Bild
- âœ… **Feste Montierung**: Keine Bewegung
- âœ… **Optimaler Abstand**: 50-100cm vom Board
- âœ… **Zentrierte Ansicht**: Board in Bildmitte

### Referenzbild
- âœ… **Komplett leer**: Keine Darts, keine HÃ¤nde
- âœ… **Alle Segmente sichtbar**: Komplettes Board
- âœ… **Scharf**: Kein Motion Blur
- âœ… **RegelmÃ¤ÃŸig erneuern**: Bei Lichtwechsel neu erstellen

### Erkennungs-QualitÃ¤t
- **Gut**: 95%+ korrekte Erkennungen
- **Akzeptabel**: 85-95% korrekt
- **Schlecht**: <85% â†’ Parameter anpassen

## ğŸ”§ Erweiterte Optimierung

### Adaptive Threshold
FÃ¼r wechselnde LichtverhÃ¤ltnisse:

```python
# Implementiere adaptive threshold
def auto_threshold(frame, reference):
    """Berechne optimalen Threshold basierend auf Bildhelligkeit"""
    avg_brightness = np.mean(frame)
    ref_brightness = np.mean(reference)
    
    brightness_diff = abs(avg_brightness - ref_brightness)
    
    if brightness_diff < 10:
        return 30  # Normal
    elif brightness_diff < 30:
        return 35  # Leichter Unterschied
    else:
        return 40  # GroÃŸer Unterschied
```

### Multi-Frame-Validierung
Reduziere Fehlerkennungen:

```python
def detect_with_validation(detector, camera, num_frames=3):
    """Erkenne Dart nur wenn in mehreren Frames erkannt"""
    detections = []
    
    for _ in range(num_frames):
        frame = camera.capture_frame()
        result = detector.detect_dart(frame)
        if result:
            detections.append(result)
        time.sleep(0.1)
    
    if len(detections) >= num_frames - 1:  # 2 von 3
        # Mittelwert der Positionen
        avg_x = sum(d.x for d in detections) / len(detections)
        avg_y = sum(d.y for d in detections) / len(detections)
        return DartCoordinate(int(avg_x), int(avg_y), 1.0, 0)
    
    return None
```

## ğŸ“ˆ Monitoring & Logging

### Erkennungs-Statistiken sammeln

```python
class DetectionStats:
    def __init__(self):
        self.total_attempts = 0
        self.successful_detections = 0
        self.false_positives = 0
        
    def log_detection(self, detected: bool, validated: bool):
        self.total_attempts += 1
        if detected:
            self.successful_detections += 1
            if not validated:
                self.false_positives += 1
    
    def accuracy(self):
        if self.total_attempts == 0:
            return 0
        return (self.successful_detections - self.false_positives) / self.total_attempts

# Verwendung
stats = DetectionStats()
# ... bei jeder Erkennung:
stats.log_detection(detected=True, validated=True)
print(f"Accuracy: {stats.accuracy():.1%}")
```

## ğŸ“ Troubleshooting

### Problem: Zu viele Fehlerkennungen
**LÃ¶sung:**
- ErhÃ¶he `threshold_value` (30 â†’ 40)
- ErhÃ¶he `min_contour_area` (100 â†’ 200)
- Verbessere Beleuchtung
- Erstelle neues Referenzbild

### Problem: Darts werden nicht erkannt
**LÃ¶sung:**
- Senke `threshold_value` (30 â†’ 25)
- Senke `min_contour_area` (100 â†’ 80)
- PrÃ¼fe Fokus der Kamera
- PrÃ¼fe ob Referenzbild aktuell ist

### Problem: Schatten werden als Darts erkannt
**LÃ¶sung:**
- Optimiere Beleuchtung (keine Schatten)
- ErhÃ¶he `threshold_value`
- Verwende Multi-Frame-Validierung

### Problem: Inkonsistente Erkennungen
**LÃ¶sung:**
- Fixiere Kamera besser (keine Bewegung)
- Verwende hÃ¶heren `blur_kernel_size`
- Erstelle neues Referenzbild bei gleichem Licht

## ğŸ“š WeiterfÃ¼hrende Optimierungen

### ZukÃ¼nftige Features (optional)
- **Maschinelles Lernen**: YOLOv8 fÃ¼r Dart-Erkennung
- **Mehrere Referenzbilder**: FÃ¼r verschiedene Lichtsituationen
- **Automatische Parameter-Anpassung**: Selbst-Kalibrierung
- **Dart-Tracking**: Bewegungsverfolgung statt Differenz

---

**Dokumentation erstellt fÃ¼r BullSight v1.0**
**Autor: Mario Neuhauser**
